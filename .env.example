# Copy this file to .env and fill in your actual values

# === API Mode Configuration ===
# Use "official" for direct API access or "proxy" for unified proxy service
API_MODE=official

# === Official API Configuration (when API_MODE=official) ===
OPENAI_API_KEY=your-openai-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
HF_TOKEN=your-huggingface-token

# Custom Base URLs for Official APIs (optional)
# Uncomment and modify if you need to use custom API endpoints
# OPENAI_BASE_URL=https://api.openai.com/v1
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# === Proxy API Configuration (when API_MODE=proxy) ===
# Uncomment and fill when using proxy mode
# PROXY_API_KEY=your-proxy-api-key
# PROXY_BASE_URL=https://openrouter.ai/api/v1

# === Model Configuration ===
# Customize the models used by the system
OPENAI_MODEL=gpt-4o
OPENAI_MINI_MODEL=gpt-4o-mini
ANTHROPIC_MODEL=claude-3-7-sonnet-20250219

# For proxy mode, you can use any models supported by your proxy service
# Examples for OpenRouter:
# OPENAI_MODEL=openai/gpt-4-turbo
# OPENAI_MINI_MODEL=openai/gpt-4o-mini
# ANTHROPIC_MODEL=anthropic/claude-3-opus-20240229

# Examples for other proxy providers:
# Together AI:
# OPENAI_MODEL=meta-llama/Llama-3-70b-chat-hf
# ANTHROPIC_MODEL=mistralai/Mixtral-8x7B-Instruct-v0.1